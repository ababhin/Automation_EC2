---
- name: Hadoop Cluster Setup
  hosts: all
  become: true

  vars:
    hadoop_version: "3.3.6"
    hadoop_download_url: "https://downloads.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    hadoop_install_dir: "/usr/local"
    hadoop_tmp_dir: "/var/tmp"

  tasks:
    - name: Install Java on Amazon Linux
      shell: |
        amazon-linux-extras enable corretto11
        yum install -y java-11-amazon-corretto
      when: ansible_distribution == "Amazon"

    - name: Ensure Hadoop temp directory exists
      file:
        path: "{{ hadoop_tmp_dir }}"
        state: directory
        owner: root
        group: root
        mode: '0755'

    - name: Download Hadoop
      get_url:
        url: "{{ hadoop_download_url }}"
        dest: "{{ hadoop_tmp_dir }}/hadoop.tar.gz"

    - name: Extract Hadoop
      unarchive:
        src: "{{ hadoop_tmp_dir }}/hadoop.tar.gz"
        dest: "{{ hadoop_install_dir }}/"
        remote_src: yes

    - name: Create Hadoop symlink
      file:
        src: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"
        dest: "{{ hadoop_install_dir }}/hadoop"
        state: link

    - name: Configure Hadoop environment variables
      lineinfile:
        path: /etc/profile.d/hadoop.sh
        create: yes
        line: "{{ item }}"
      with_items:
        - 'export HADOOP_HOME={{ hadoop_install_dir }}/hadoop'
        - 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin'
        - 'export JAVA_HOME=/usr/lib/jvm/java-11-amazon-corretto'

    - name: Source Hadoop environment variables
      shell: source /etc/profile.d/hadoop.sh
      args:
        executable: /bin/bash

    - name: Copy Hadoop Configuration Files
      template:
        src: templates/{{ item }}
        dest: "{{ hadoop_install_dir }}/hadoop/etc/hadoop/{{ item }}"
      with_items:
        - core-site.xml
        - hdfs-site.xml
        - yarn-site.xml
        - mapred-site.xml

    - name: Create Hadoop directories for HDFS
      file:
        path: "{{ item }}"
        state: directory
        owner: hadoop
        group: hadoop
        mode: '0755'
      with_items:
        - /usr/local/hadoop_data/hdfs/namenode
        - /usr/local/hadoop_data/hdfs/datanode
      when: "'namenode' in group_names or 'datanodes' in group_names"

    - name: Format HDFS (NameNode only)
      shell: hdfs namenode -format
      when: "'namenode' in group_names"

    - name: Start Hadoop Services (NameNode)
      shell: |
        start-dfs.sh
        start-yarn.sh
      when: "'namenode' in group_names"

    - name: Start DataNode Services
      shell: |
        start-dfs.sh
      when: "'datanodes' in group_names"

    - name: Clean up temporary files
      file:
        path: "{{ hadoop_tmp_dir }}/hadoop.tar.gz"
        state: absent
